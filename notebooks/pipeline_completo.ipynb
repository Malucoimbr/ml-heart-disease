{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8200672",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da7c0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sqlalchemy import create_engine, text\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Setup\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc5b8d2",
   "metadata": {},
   "source": [
    "# Extração dos dados do PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a4f007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURAÇÃO DE CONEXÃO COM POSTGRESQL ---\n",
    "# As variáveis são lidas do ambiente Docker injetado pelo docker-compose\n",
    "POSTGRES_USER = os.environ.get(\"POSTGRES_USER\")\n",
    "POSTGRES_PASSWORD = os.environ.get(\"POSTGRES_PASSWORD\")\n",
    "POSTGRES_DB = os.environ.get(\"POSTGRES_DB\")\n",
    "DB_HOST = os.environ.get(\"DB_HOST\") \n",
    "RAW_TABLE_NAME = \"heart_disease_raw\" # A tabela que o FastAPI carrega\n",
    "\n",
    "DATABASE_URL = f\"postgresql://{POSTGRES_USER}:{POSTGRES_PASSWORD}@{DB_HOST}:5432/{POSTGRES_DB}\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# --- AÇÃO CHAVE: LER A TABELA PERSISTIDA PARA O DATAFRAME 'df' ---\n",
    "try:\n",
    "    # Lendo o DataFrame diretamente da tabela que contém os dados brutos\n",
    "    df = pd.read_sql(text(f\"SELECT * FROM {RAW_TABLE_NAME}\"), engine)\n",
    "    \n",
    "    print(f\"VERIFICAÇÃO: DataFrame 'df' lido com sucesso da tabela PostgreSQL: {RAW_TABLE_NAME}\")\n",
    "    print(f\"Total de linhas para limpeza: {len(df)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ERRO CRÍTICO AO LER DO POSTGRESQL!\")\n",
    "    print(\"O FastAPI /load_raw_to_db/ falhou ou o pg_db não está pronto.\")\n",
    "    print(f\"Erro: {e}\")\n",
    "    print(\"=\"*50)\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e39871",
   "metadata": {},
   "source": [
    "# Tratamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb7143d",
   "metadata": {},
   "source": [
    "## Limpeza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c5354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== 1. Remoção das duplicatas =====\n",
    "df_sem_duplicatas = df.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(\"Linhas antes:\", len(df))\n",
    "print(\"Linhas depois da remoção de duplicatas:\", len(df_sem_duplicatas))\n",
    "\n",
    "# ===== 2. Substituição dos valores impossíveis =====\n",
    "# Valores impossíveis identificados:\n",
    "# resting bp s: 0\n",
    "# cholesterol: 0\n",
    "\n",
    "df_clean = df_sem_duplicatas.copy()\n",
    "\n",
    "# Substituir resting bp s = 0 pela mediana (ignorando os zeros)\n",
    "rbp_median = df_clean.loc[df_clean[\"resting bp s\"] > 0, \"resting bp s\"].median()\n",
    "df_clean.loc[df_clean[\"resting bp s\"] == 0, \"resting bp s\"] = rbp_median\n",
    "\n",
    "# Substituir cholesterol = 0 pela mediana\n",
    "chol_median = df_clean.loc[df_clean[\"cholesterol\"] > 0, \"cholesterol\"].median()\n",
    "df_clean.loc[df_clean[\"cholesterol\"] == 0, \"cholesterol\"] = chol_median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4227f034",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bed388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colunas categóricas a converter\n",
    "categorical_cols = [\"chest pain type\", \"resting ecg\", \"ST slope\"]\n",
    "\n",
    "# OneHotEncoder com drop='first' evita multicolinearidade\n",
    "ohe = OneHotEncoder(drop=None, sparse_output=False)\n",
    "\n",
    "# Ajustar e transformar\n",
    "encoded = ohe.fit_transform(df_clean[categorical_cols])\n",
    "\n",
    "# Novo dataframe codificado\n",
    "encoded_df = pd.DataFrame(encoded, \n",
    "                          columns=ohe.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Remover colunas originais e substituir pelas novas\n",
    "df_encoded = pd.concat([df_clean.drop(columns=categorical_cols).reset_index(drop=True),\n",
    "                        encoded_df.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261070e8",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e1b91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar numericas e categoricas\n",
    "num_cols = [\"age\", \"resting bp s\", \"cholesterol\",\n",
    "            \"fasting blood sugar\", \"max heart rate\", \"oldpeak\"]\n",
    "\n",
    "# Copiar dataset para não sujar o original\n",
    "df_scaled = df_encoded.copy()\n",
    "\n",
    "# Aplicar o scaler\n",
    "scaler = StandardScaler()\n",
    "df_scaled[num_cols] = scaler.fit_transform(df_scaled[num_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eb45b9",
   "metadata": {},
   "source": [
    "# Split dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870232c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_scaled.copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
